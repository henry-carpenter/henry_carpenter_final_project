{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Henry Carpenter - Final Project, Part 1: Proposal\n",
    "\n",
    "Airbnb - and other similar peer-to-peer hospitality services like it - have proven to be more than just a flash in the pan in the crowded lodging marketplace. [Recent estimates](https://muchneeded.com/airbnb-statistics/) have put Airbnb's total historical usage at more than 260 million stays covering over 65,000 cities and 5 million listings.\n",
    "\n",
    "With so many guests choosing Airbnb over hotels, it makes sense that property owners offering their abode to strangers would set their nightly rates such that their own net profit is maximized. This is little more than a mildly complex econometrics problem. Although I won't be applying rigorous economic theory to seek an answer to the question \"What should I charge per night for my spare bedroom?\" I can leverage some basic machine learning techniques in this pursuit. From Kaggle, I have found [a robust database](https://www.kaggle.com/brittabettendorf/berlin-airbnb-data/downloads/berlin-airbnb-data.zip/2) covering all aspects of Airbnb listings in Berlin, Germany, including listing information and summaries, neighborhood information, reviews and review summaries, and calendar information.\n",
    "\n",
    "Unfortunately, the dataset (unsurprisingly) does not contain a field named 'Fair Market List Price,' but for the sake of this project, I will assume that basic free-market principles are prevailing and beds are being listed for what is their fair market price. Thus, my target variable will be 'Price.'\n",
    "\n",
    "There are a great many possible variables I could use to attempt to arrive at the best price. Some of those which stand out initially include but are not limited to: neighborhood, room type, minimum nights, number of reviews, date, host gender, and more.\n",
    "\n",
    "After a run-over of the datasets, I am confident that there is enough meaningful signal present that I could produce a model of at least mild utility. I have no fear that I will run short of training data, and it all seems standardized enough where it can be that with sufficient pre-processing, the data will prove useful.\n",
    "\n",
    "It is difficult to say initially what my threshold will be for a successful model. It makes more sense to me right now to prioritize using RMSE over MAE, as very wrong answers do matter to me, but I don't have a sense of what I would consider a \"good\" r-squared to be.\n",
    "\n",
    "Probably the trickiest part of the problem as I currently see it is the relative dearth of quantitative information in the problem set. There is no field for things like \"distance from nearest city center,\" \"square footage,\" or much else. Rather, the majority of the data is categorical. This is not a deal-breaker, but it means that there is less \"hard\" numbers to work with, and those can be nice to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df = pd.read_csv('./listings.csv')\n",
    "neighbourhoods_df = pd.read_csv('./neighbourhoods.csv')\n",
    "reviews_df = pd.read_csv('./reviews.csv')\n",
    "\n",
    "#  File too big to upload directly to GitHub, I will either trim it down or split into pieces soon\n",
    "#  calendar_df = pd.read_csv('./calendar_summary.csv') \n",
    "\n",
    "#  File too big to upload directly to GitHub, I will either trim it down or split into pieces soon\n",
    "#  listings_summary_df = pd.read_csv('./listings_summary.csv')\n",
    "\n",
    "#  File too big to upload directly to GitHub, I will either trim it down or split into pieces soon\n",
    "#  reviews_summary_df = pd.read_csv('./reviews_summary.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calendar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  listings_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  reviews_summary_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
